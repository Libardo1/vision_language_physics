@article{Battaglia2013,
author = {Battaglia, P. W. and Hamrick, J. B. and Tenenbaum, J. B.},
doi = {10.1073/pnas.1306572110},
file = {:Users/malmaud/Dropbox/Documents/Mendeley Desktop/PNAS-2013-Battaglia-18327-32.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
number = {45},
pages = {18327--18332},
title = {{Simulation as an engine of physical scene understanding}},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1306572110},
volume = {110},
year = {2013}
}
@article{D.Xie2013,
author = {{D. Xie}, S. Todorovic and S.C. Zhu},
file = {:Users/malmaud/Dropbox/Documents/Mendeley Desktop/Darkmatter{\_}iccv{\_}2013.pdf:pdf},
journal = {Proc. Int’l Conference on Computer Vision (ICCV)},
title = {{Inferring “Dark Matter” and “Dark Energy” from Videos.pdf}},
year = {2013}
}
@article{Mottaghi2015,
abstract = {In this paper, we study the challenging problem of predicting the dynamics of objects in static images. Given a query object in an image, our goal is to provide a physical understanding of the object in terms of the forces acting upon it and its long term motion as response to those forces. Direct and explicit estimation of the forces and the motion of objects from a single image is extremely challenging. We define intermediate physical abstractions called Newtonian scenarios and introduce Newtonian Neural Network ({\$}N{\^{}}3{\$}) that learns to map a single image to a state in a Newtonian scenario. Our experimental evaluations show that our method can reliably predict dynamics of a query object from a single image. In addition, our approach can provide physical reasoning that supports the predicted dynamics in terms of velocity and force vectors. To spur research in this direction we compiled Visual Newtonian Dynamics (VIND) dataset that includes 6806 videos aligned with Newtonian scenarios represented using game engines, and 4516 still images with their ground truth dynamics.},
archivePrefix = {arXiv},
arxivId = {1511.04048},
author = {Mottaghi, Roozbeh and Bagherinezhad, Hessam and Rastegari, Mohammad and Farhadi, Ali},
eprint = {1511.04048},
file = {:Users/malmaud/Dropbox/Documents/Mendeley Desktop/1511.04048v1.pdf:pdf},
title = {{Newtonian Image Understanding: Unfolding the Dynamics of Objects in Static Images}},
url = {http://arxiv.org/abs/1511.04048},
year = {2015}
}
@article{Siddharth2014,
archivePrefix = {arXiv},
arxivId = {arXiv:1308.4189v1},
author = {Siddharth, N and Barbu, Andrei and Siskind, Jeffrey Mark},
doi = {10.1109/CVPR.2014.99},
eprint = {arXiv:1308.4189v1},
file = {:Users/malmaud/Dropbox/Documents/Mendeley Desktop/siddharth2013activityRecognition.pdf:pdf},
journal = {Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on},
title = {{Seeing What You ’ re Told : Sentence-Guided Activity Recognition In Video}},
year = {2014}
}
@misc{Talmy1988,
abstract = {"Force dynamics" refers to a previously neglected semantic category-how entities interact with respect to force. This category includes such concepts as: the exertion of force, resistance to such exertion and the overcoming of such resistance, blockage of a force and the removal of such blockage, and so forth. Force dynamics is a generalization over the traditional linguistic notion of "causative": it analyzes "causing" into finer primitives and sets it naturally within a framework that also includes "letting," "hindering," "helping," and still further notions. Force dynamics, moreover, appears to be the semantic category that uniquely characterizes the grammatical category of modals, in both their basic and epistemic usages. In addition, on the basis of force dynamic parameters, numerous lexical items fall into systematic semantic patterns, and there exhibit parallelisms between physical and psychosocial reference. Further, from research on the relation of semantic structure to general cognitive structure, it appears that the concepts of force interaction that are encoded within language closely parallel concepts that appear both in early science and in naive physics and psychology. Overall, force dynamics thus emerges as a fundamental notional system that structures conceptual material pertaining to force interaction in a common way across a linguistic range: the physical, psychological, social, inferential, discourse, and mental-model domains of reference and conception. ?? 1988.},
author = {Talmy, Leonard},
booktitle = {Cognitive Science},
doi = {10.1016/0364-0213(88)90008-0},
file = {:Users/malmaud/Dropbox/Documents/Mendeley Desktop/Force Dynamics in Language and Cognition, Talmy, 1988.pdf:pdf},
isbn = {0262700964},
issn = {03640213},
number = {1},
pages = {49--100},
title = {{Force dynamics in language and cognition}},
volume = {12},
year = {1988}
}
@article{White2012,
abstract = {Several tendencies found in explicit judgments about object motion have been interpreted as evidence that people possess a naive theory of impetus. The theory states that objects that are caused to move by other objects acquire force that determines the kind of motion exhibited by the object, and that this force gradually dissipates over time. I argue that the findings can better be understood as manifestations of a general understanding of externally caused motion based on experiences of acting on objects. Experiences of acting on objects yield the idea that properties of the cause of motion are transmitted to the effect object. This idea functions as a heuristic for explicit predictions of object motion under conditions of uncertainty. This accounts not only for the findings taken as evidence for the impetus theory, but also for several findings that fall outside the scope of the impetus theory. It has also been claimed that judgments about the location at which a moving object disappeared are influenced by the impetus theory. I argue that these judgments are better explained in a different way, as best-guess extrapolations made by the visual system as a practical guide to interactions with the object, such as interception.},
author = {White, Peter A.},
doi = {10.3758/s13423-012-0302-2},
file = {:Users/malmaud/Dropbox/Documents/Mendeley Desktop/art{\%}3A10.3758{\%}2Fs13423-012-0302-2.pdf:pdf},
issn = {1069-9384},
journal = {Psychonomic Bulletin {\&} Review},
keywords = {by,either,everyone has abundant experience,from observing objects in,high-order cognition,impetus theory,motion,of moving objects,representational momentum,such as balls propelled},
pages = {1007--1028},
pmid = {22851410},
title = {{The impetus theory in judgments about object motion: A new perspective}},
year = {2012}
}
@article{Siskind2001,
author = {Siskind, J},
file = {:Users/malmaud/Dropbox/Documents/Mendeley Desktop/live-790-1936-jair.pdf:pdf},
journal = {Journal of AI Research},
pages = {31--90},
title = {{Grounding Lexical Semantics of Verbs in Visual Perception Using Force Dynamics and Even Logic}},
volume = {15},
year = {2001}
}
@article{Wolff2007,
author = {Wolff, Phillip},
file = {:Users/malmaud/Dropbox/Documents/Mendeley Desktop/Wolff2007proofs.pdf:pdf},
journal = {Journal of experimental psychology. General},
number = {1},
pages = {82},
title = {{Representing causation}},
volume = {136},
year = {2007}
}
@article{Brubaker2009,
abstract = {Motion and interaction with the environment are fundamentally intertwined. Few people-tracking algorithms exploit such interactions, and those that do assume that surface geometry and dynamics are given. This paper concerns the converse problem, i.e., the inference of contact and environment properties from motion. For 3D human motion, with a 12-segment articulated body model, we show how one can estimate the forces acting on the body in terms of internal forces (joint torques), gravity, and the parameters of a contact model (e.g., the geometry and dynamics of a spring-based model). This is tested on motion capture data and video-based tracking data, with walking, jogging, cartwheels, and jumping.},
author = {Brubaker, Marcus A and Sigal, Leonid and Fleet, David J},
doi = {10.1109/ICCV.2009.5459407},
file = {:Users/malmaud/Dropbox/Documents/Mendeley Desktop/contactDynamicsICCV09.pdf:pdf},
isbn = {978-1-4244-4420-5},
issn = {1550-5499},
journal = {IEEE 12th International Conference on Computer Vision},
number = {Iccv},
pages = {2389--2396},
title = {{Estimating Contact Dynamics}},
year = {2009}
}
@article{Roy2004,
abstract = {To build robots that engage in fluid face-to-face spoken conversations with people, robots must have ways to connect what they say to what they see. A critical aspect of how language connects to vision is that language encodes points of view. The meaning of my left and your left differs due to an implied shift of visual perspective. The connection of language to vision also relies on object permanence. We can talk about things that are not in view. For a robot to participate in situated spoken dialog, it must have the capacity to imagine shifts of perspective, and it must maintain object permanence. We present a set of representations and procedures that enable a robotic manipulator to maintain a "mental model" of its physical environment by coupling active vision to physical simulation. Within this model, "imagined" views can be generated from arbitrary perspectives, providing the basis for situated language comprehension and production. An initial application of mental imagery for spatial language understanding for an interactive robot is described.},
author = {Roy, Deb and Hsiao, Kai Yuh and Mavridis, Nikolaos},
doi = {10.1109/TSMCB.2004.823327},
file = {:Users/malmaud/Dropbox/Documents/Mendeley Desktop/10.1.1.139.2459.pdf:pdf},
isbn = {1083-4419},
issn = {10834419},
journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics},
keywords = {Active vision,Grounding,Language,Mental imagery,Mental models,Mental simulation,Robots},
number = {3},
pages = {1374--1383},
pmid = {15484910},
title = {{Mental imagery for a conversational robot}},
volume = {34},
year = {2004}
}
@article{Fern2006,
abstract = {We present a trainable sequential-inference technique for processes with large state and observation spaces and relational structure. We apply our technique to the problem of force-dynamic state inference from video, which is a critical component of the LEONARD [J.M. Siskind, Grounding lexical semantics of verbs in visual perception using force dynamics and event logic, Journal of Artificial Intelligence Research 15 (2001) 31-90] visual-event recognition system. LEONARD uses event definitions that are grounded in force-dynamic primitives-making robust and efficient force-dynamic inference critical to good performance. Our sequential-inference method assumes "reliable observations", i.e., that each process state (e.g., force-dynamic state) persists long enough to be reliably inferred from the observations (e.g., video frames) it generates. We introduce the idea of a "state-inference function" (from observation sequences to underlying hidden states) for representing knowledge about a process and develop an efficient sequential-inference algorithm, utilizing this function, that is correct for processes that generate reliable observations consistent with the state-inference function. We describe a representation for state-inference functions in relational domains and give a corresponding supervised learning algorithm. Our experiments in force-dynamic state inference show that our technique provides significantly improved accuracy and speed relative to a variety of recent, hand-coded, non-trainable systems, and a trainable system based on probabilistic modeling. ?? 2006.},
author = {Fern, Alan and Givan, Robert},
doi = {10.1016/j.artint.2006.08.003},
file = {:Users/malmaud/Dropbox/Documents/Mendeley Desktop/1-s2.0-S0004370206000786-main.pdf:pdf},
isbn = {1581138385 (ISBN)},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Event recognition,Inductive logic programming,Relational learning,Sequence learning,Temporal learning},
number = {14-15},
pages = {1081--1100},
title = {{Sequential inference with reliable observations: Learning to construct force-dynamic models}},
volume = {170},
year = {2006}
}
@article{Glenberg2002,
author = {Glenberg, Arthur M and Kaschak, Michael P},
file = {:Users/malmaud/Dropbox/Documents/Mendeley Desktop/glenberg.lang-action.psychrevbul02.pdf:pdf},
number = {3},
pages = {558--565},
title = {{Grounding language in action}},
volume = {9},
year = {2002}
}
