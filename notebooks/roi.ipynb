{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_table=pandas.read_table(\"/storage/malmaud/tmp/train.txt\", sep=\" \",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>box</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/storage/malmaud/kinect/hinder1/color/frames/o...</td>\n",
       "      <td>3</td>\n",
       "      <td>1309.333333</td>\n",
       "      <td>816.000000</td>\n",
       "      <td>1498.666667</td>\n",
       "      <td>898.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/storage/malmaud/kinect/hinder1/color/frames/o...</td>\n",
       "      <td>3</td>\n",
       "      <td>1306.666667</td>\n",
       "      <td>816.000000</td>\n",
       "      <td>1496.000000</td>\n",
       "      <td>901.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/storage/malmaud/kinect/hinder1/color/frames/o...</td>\n",
       "      <td>3</td>\n",
       "      <td>1306.666667</td>\n",
       "      <td>818.666667</td>\n",
       "      <td>1496.000000</td>\n",
       "      <td>904.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/storage/malmaud/kinect/hinder1/color/frames/o...</td>\n",
       "      <td>3</td>\n",
       "      <td>1306.666667</td>\n",
       "      <td>821.333333</td>\n",
       "      <td>1496.000000</td>\n",
       "      <td>906.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/storage/malmaud/kinect/hinder1/color/frames/o...</td>\n",
       "      <td>3</td>\n",
       "      <td>1322.666667</td>\n",
       "      <td>901.333333</td>\n",
       "      <td>1528.000000</td>\n",
       "      <td>1018.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file  box           x1  \\\n",
       "0  /storage/malmaud/kinect/hinder1/color/frames/o...    3  1309.333333   \n",
       "1  /storage/malmaud/kinect/hinder1/color/frames/o...    3  1306.666667   \n",
       "2  /storage/malmaud/kinect/hinder1/color/frames/o...    3  1306.666667   \n",
       "3  /storage/malmaud/kinect/hinder1/color/frames/o...    3  1306.666667   \n",
       "4  /storage/malmaud/kinect/hinder1/color/frames/o...    3  1322.666667   \n",
       "\n",
       "           y1           x2           y2  \n",
       "0  816.000000  1498.666667   898.666667  \n",
       "1  816.000000  1496.000000   901.333333  \n",
       "2  818.666667  1496.000000   904.000000  \n",
       "3  821.333333  1496.000000   906.666667  \n",
       "4  901.333333  1528.000000  1018.666667  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_table.columns=[\"file\",\"box\",\"x1\",\"y1\",\"x2\",\"y2\"]\n",
    "training_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_label(filename):\n",
    "    m = re.match(r\".*/(.*?)\\d?/color.*\", filename)\n",
    "    return m.groups()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels=np.unique([get_label(file) for file in training_table['file']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_labels=len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = np.unique(training_table[\"file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files=files[:194*batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename= tf.placeholder(tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = tf.image.decode_jpeg(tf.read_file(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=tf.placeholder(tf.float32, [None, 1080, 1920, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1=tf.Variable(tf.random_normal([3, 3, 3, 5], stddev=.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X1=tf.nn.conv2d(X, W1, [1,1,1,1],'VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X2=tf.nn.max_pool(X1, [1,2,2,1],[1,2,2,1],'VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(539), Dimension(959), Dimension(5)])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=np.zeros([batch_size,1080,1920,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=np.zeros([batch_size, N_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W=tf.Variable(tf.random_normal([539*959*5, N_labels], stddev=.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_flat=tf.reshape(X2,[batch_size, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y=tf.nn.softmax(tf.matmul(X_flat, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Yhat = tf.placeholder(tf.float32, [None, N_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(-Yhat * Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradW = tf.gradients(loss, [W, W1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha=.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is -0.00000\n",
      "Loss is -0.00000\n",
      "Loss is -0.00004\n",
      "Loss is -7.95540\n",
      "Loss is -8.00000\n",
      "Loss is -8.00000\n",
      "Loss is -7.00000\n",
      "Loss is -6.00000\n",
      "Loss is -9.00000\n",
      "On image 100/1940\n",
      "Loss is -7.00000\n",
      "Loss is -9.00000\n",
      "Loss is -8.00000\n",
      "Loss is -8.00000\n",
      "Loss is -9.00000\n",
      "Loss is -7.00000\n",
      "Loss is -7.00000\n",
      "Loss is -9.00000\n",
      "Loss is -8.00000\n",
      "Loss is -8.00000\n",
      "On image 200/1940\n",
      "Loss is -9.00000\n",
      "Loss is -9.00000\n",
      "Loss is -9.00000\n",
      "Loss is -8.00000\n",
      "Loss is -8.00000\n",
      "Loss is -10.00000\n",
      "Loss is -9.00000\n",
      "Loss is -6.00000\n",
      "Loss is -7.00000\n",
      "Loss is -10.00000\n",
      "On image 300/1940\n",
      "Loss is -9.00000\n",
      "Loss is -6.00000\n",
      "Loss is -9.00000\n",
      "Loss is -8.00000\n",
      "Loss is -7.00000\n",
      "Loss is -9.00000\n",
      "Loss is -10.00000\n",
      "Loss is -7.00000\n",
      "Loss is -8.00000\n",
      "Loss is -8.00000\n",
      "On image 400/1940\n",
      "Loss is -8.00000\n",
      "Loss is -9.00000\n",
      "Loss is -7.00000\n",
      "Loss is -7.00000\n",
      "Loss is -8.00000\n",
      "Loss is -7.00000\n",
      "Loss is -8.00000\n",
      "Loss is -8.00000\n",
      "Loss is -10.00000\n",
      "Loss is -9.00000\n",
      "On image 500/1940\n",
      "Loss is -6.00000\n",
      "Loss is -9.00000\n",
      "Loss is -7.00000\n",
      "Loss is -6.00000\n",
      "Loss is -9.00000\n",
      "Loss is -8.00000\n",
      "Loss is -6.00000\n",
      "Loss is -9.00000\n",
      "Loss is -6.00000\n",
      "Loss is -10.00000\n",
      "On image 600/1940\n",
      "Loss is -8.00000\n",
      "Loss is -9.00000\n",
      "Loss is -9.00000\n",
      "Loss is -6.00000\n",
      "Loss is -7.00000\n",
      "Loss is -8.00000\n",
      "Loss is -7.00000\n",
      "Loss is -9.00000\n",
      "Loss is -9.00000\n",
      "Loss is -9.00000\n",
      "On image 700/1940\n",
      "Loss is -7.00000\n",
      "Loss is -7.00000\n",
      "Loss is -9.00000\n",
      "Loss is -10.00000\n",
      "Loss is -7.00000\n",
      "Loss is -8.00000\n",
      "Loss is -9.00000\n",
      "Loss is -9.00000\n",
      "Loss is -7.00000\n",
      "Loss is -8.00000\n",
      "On image 800/1940\n",
      "Loss is -5.00000\n",
      "Loss is -9.00000\n",
      "Loss is -8.00000\n",
      "Loss is -7.00000\n",
      "Loss is -7.00000\n",
      "Loss is -9.00000\n",
      "Loss is -7.00000\n",
      "Loss is -8.00000\n",
      "Loss is -9.00000\n",
      "Loss is -8.00000\n",
      "On image 900/1940\n",
      "Loss is -8.00000\n",
      "Loss is -9.00000\n",
      "Loss is -8.00000\n",
      "Loss is -7.00000\n",
      "Loss is -8.00000\n",
      "Loss is -8.00000\n",
      "Loss is -7.00000\n",
      "Loss is -8.00000\n",
      "Loss is -7.00000\n",
      "Loss is -9.00000\n",
      "On image 1000/1940\n",
      "Loss is -9.00000\n",
      "Loss is -6.00000\n",
      "Loss is -8.00000\n",
      "Loss is -7.00000\n",
      "Loss is -8.00000\n",
      "Loss is -9.00000\n",
      "Loss is -6.00000\n",
      "Loss is -8.00000\n",
      "Loss is -9.00000\n",
      "Loss is -9.00000\n",
      "On image 1100/1940\n",
      "Loss is -10.00000\n",
      "Loss is -8.00000\n",
      "Loss is -8.00000\n",
      "Loss is -6.00000\n",
      "Loss is -5.00000\n",
      "Loss is -7.00000\n",
      "Loss is -9.00000\n",
      "Loss is -7.00000\n",
      "Loss is -9.00000\n",
      "Loss is -8.00000\n",
      "On image 1200/1940\n",
      "Loss is -7.00000\n",
      "Loss is -8.00000\n",
      "Loss is -7.00000\n",
      "Loss is -9.00000\n",
      "Loss is -10.00000\n",
      "Loss is -9.00000\n",
      "Loss is -5.00000\n",
      "Loss is -5.00000\n",
      "Loss is -8.00000\n",
      "Loss is -8.00000\n",
      "On image 1300/1940\n",
      "Loss is -10.00000\n",
      "Loss is -10.00000\n",
      "Loss is -8.00000\n",
      "Loss is -9.00000\n",
      "Loss is -9.00000\n",
      "Loss is -8.00000\n",
      "Loss is -9.00000\n",
      "Loss is -7.00000\n",
      "Loss is -8.00000\n",
      "Loss is -9.00000\n",
      "On image 1400/1940\n",
      "Loss is -7.00000\n",
      "Loss is -8.00000\n",
      "Loss is -8.00000\n",
      "Loss is -9.00000\n",
      "Loss is -7.00000\n",
      "Loss is -9.00000\n",
      "Loss is -8.00000\n",
      "Loss is -6.00000\n",
      "Loss is -8.00000\n",
      "Loss is -9.00000\n",
      "On image 1500/1940\n",
      "Loss is -8.00000\n",
      "Loss is -6.00000\n",
      "Loss is -6.00000\n",
      "Loss is -10.00000\n",
      "Loss is -7.00000\n",
      "Loss is -7.00000\n",
      "Loss is -9.00000\n",
      "Loss is -7.00000\n",
      "Loss is -9.00000\n",
      "Loss is -9.00000\n",
      "On image 1600/1940\n",
      "Loss is -7.00000\n",
      "Loss is -9.00000\n",
      "Loss is -8.00000\n",
      "Loss is -8.00000\n",
      "Loss is -8.00000\n",
      "Loss is -10.00000\n",
      "Loss is -9.00000\n",
      "Loss is -9.00000\n",
      "Loss is -8.00000\n",
      "Loss is -7.00000\n",
      "On image 1700/1940\n",
      "Loss is -9.00000\n",
      "Loss is -10.00000\n",
      "Loss is -9.00000\n",
      "Loss is -8.00000\n",
      "Loss is -8.00000\n",
      "Loss is -9.00000\n",
      "Loss is -8.00000\n",
      "Loss is -7.00000\n",
      "Loss is -7.00000\n",
      "Loss is -7.00000\n",
      "On image 1800/1940\n",
      "Loss is -7.00000\n",
      "Loss is -8.00000\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10,5,539,959]\n\t [[Node: gradients/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Conv2D, MaxPool, gradients/Reshape_grad/Reshape)]]\n\t [[Node: gradients/Conv2D_grad/Conv2DBackpropFilter/_17 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_135_gradients/Conv2D_grad/Conv2DBackpropFilter\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'gradients/MaxPool_grad/MaxPoolGrad', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-30-6f3577cb6382>\", line 1, in <module>\n    gradW = tf.gradients(loss, [W, W1])\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py\", line 481, in gradients\n    in_grads = _AsList(grad_fn(op, *out_grads))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_grad.py\", line 251, in _MaxPoolGrad\n    data_format=op.get_attr(\"data_format\")\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 710, in _max_pool_grad\n    data_format=data_format, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'MaxPool', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 17 identical lines from previous traceback]\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-186c25d3d084>\", line 1, in <module>\n    X2=tf.nn.max_pool(X1, [1,2,2,1],[1,2,2,1],'VALID')\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 341, in max_pool\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 677, in _max_pool\n    data_format=data_format, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-6a6733961df8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mimg_id\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[1;34m\"On image %s/%s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mgW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgradW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYhat\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Loss is %.5f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign_sub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign_sub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgW1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 340\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    341\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 564\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    565\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m       \u001b[1;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 637\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    638\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    657\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m       raise errors._make_specific_exception(node_def, op, error_message,\n\u001b[1;32m--> 659\u001b[1;33m                                             e.code)\n\u001b[0m\u001b[0;32m    660\u001b[0m       \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10,5,539,959]\n\t [[Node: gradients/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Conv2D, MaxPool, gradients/Reshape_grad/Reshape)]]\n\t [[Node: gradients/Conv2D_grad/Conv2DBackpropFilter/_17 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_135_gradients/Conv2D_grad/Conv2DBackpropFilter\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'gradients/MaxPool_grad/MaxPoolGrad', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-30-6f3577cb6382>\", line 1, in <module>\n    gradW = tf.gradients(loss, [W, W1])\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py\", line 481, in gradients\n    in_grads = _AsList(grad_fn(op, *out_grads))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_grad.py\", line 251, in _MaxPoolGrad\n    data_format=op.get_attr(\"data_format\")\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 710, in _max_pool_grad\n    data_format=data_format, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'MaxPool', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 17 identical lines from previous traceback]\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-186c25d3d084>\", line 1, in <module>\n    X2=tf.nn.max_pool(X1, [1,2,2,1],[1,2,2,1],'VALID')\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 341, in max_pool\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 677, in _max_pool\n    data_format=data_format, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "img_id=0\n",
    "sess.run(tf.initialize_all_variables())\n",
    "while img_id < len(files):\n",
    "    y[:] = 0\n",
    "    for i in range(batch_size):\n",
    "        x[i, :, :, :] = sess.run(img, feed_dict={filename: files[img_id]})\n",
    "        label = get_label(files[img_id])\n",
    "        for j in range(N_labels):\n",
    "            if labels[j] == label:\n",
    "                y[i, j] = 1.0\n",
    "                break\n",
    "        img_id+=1\n",
    "        if img_id%100==0:\n",
    "            print \"On image %s/%s\" % (img_id, len(files))\n",
    "    gW, gW1, l = sess.run([gradW[0], gradW[1], loss], feed_dict={X: x, Yhat: y})\n",
    "    print \"Loss is %.5f\" % l\n",
    "    sess.run([W.assign_sub(alpha*gW), W1.assign_sub(alpha*gW1)])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
